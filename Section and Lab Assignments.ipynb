{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from scipy.sparse import lil_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster = pd.read_csv(\"roster.csv\") # from cal central\n",
    "prefs_form = pd.read_csv(\"prefs.csv\") # from Google Forms\n",
    "joined = roster.merge(prefs_form, left_on='Email Address', right_on=\"Email Address\")\n",
    "\n",
    "# All the columns in the preferences table have the workd \"preferences\" in them\n",
    "lab_cols = [c for c in joined.columns if \"preferences for lab\" in c.lower()]\n",
    "sec_cols = [c for c in joined.columns if \"discussion\" in c.lower()]\n",
    "util_map = {\n",
    "    \"Cannot make this time.\": 0.,\n",
    "    \"Least Preferred\": 1.,\n",
    "    \"Moderately Preferred\": 2.,\n",
    "    \"Strongly Preferred\": 3.,\n",
    "    \"Strong Preferred\": 3. #oops typo in form.\n",
    "}\n",
    "# Convert strings to utility scores\n",
    "lab_prefs = joined[lab_cols].replace(util_map)\n",
    "sec_prefs = joined[sec_cols].replace(util_map)\n",
    "\n",
    "# Print dimensions\n",
    "(n_students, n_labs) = lab_prefs.shape\n",
    "(n_students, n_sections) = sec_prefs.shape\n",
    "print(\"Number of Students:\", n_students)\n",
    "print(\"Number of Labs:\", n_labs)\n",
    "print(\"Number of Sections:\", n_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting The Section and Lab Sizes\n",
    "\n",
    "This needs to be updated to reflect actual capacity or remaining capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_sizes = np.ones(n_sections) * 35\n",
    "lab_sizes = np.ones(n_labs) * 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lp(prefs, cap, fuzzing=1.0e-5):\n",
    "    \"\"\"\n",
    "    This function returns the optimal section assignments\n",
    "    \n",
    "    prefs is an n_students by n_sections matrix of utility values. Larger values are better.\n",
    "    cap is an n_sections vector of section sizes.\n",
    "    \"\"\"\n",
    "    \n",
    "    (n,d) = prefs.shape\n",
    "    \n",
    "    # The optimizer MINIMIZES the sum of the weights.\n",
    "    w = -prefs.flatten() # prefs is in row major form. \n",
    "\n",
    "    ### This is a bit of a hack but the problem is not well conditioned \n",
    "    ### so by adding a small amount of noise we ensure a single solution.\n",
    "    w += fuzzing * np.random.randn(len(w)) \n",
    "    \n",
    "    # The equality constraints enforces that every student is in one section\n",
    "    # Each row in Aeq is the constrain for a single student\n",
    "    Aeq = lil_matrix((n, n*d))\n",
    "    for i in range(n):\n",
    "        Aeq[i,(i*d):((i+1)*d)] = 1.\n",
    "    Aeq = Aeq.asformat(\"csr\")\n",
    "    # Note we will also add a 0 < x < 1 constraint in the bounds arg to linprog\n",
    "    \n",
    "    # The inequality constraint ensures that no room has too many students\n",
    "    Aub = lil_matrix((d, n*d))\n",
    "    for i in range(d):\n",
    "        tmp = np.zeros((n,d))\n",
    "        tmp[:,i] = 1.\n",
    "        Aub[i,:] = tmp.flatten()\n",
    "    Aub = Aub.asformat(\"csr\")\n",
    "    \n",
    "    options = dict(\n",
    "        sparse=True, # Treat the constraint matrices as sparse\n",
    "#         maxiter=100000,\n",
    "#         tol=1.0e-10,\n",
    "        disp=False)\n",
    "    \n",
    "    res = opt.linprog(w, Aub, cap, Aeq, np.ones(n), bounds = (0,1), options=options)\n",
    "    return res\n",
    "\n",
    "def compute_assignments(prefs, cap, unhappy = 0.0):\n",
    "    \"\"\"\n",
    "    Compute the section assignments from the output of the optimization.\n",
    "    prefs: pandas dataframes of section preferences used for the optimization\n",
    "    cap: a numpy array of the section sizes\n",
    "    \"\"\"\n",
    "    soln = run_lp(prefs.to_numpy(), cap)\n",
    "    (n,d) = prefs.shape\n",
    "    rounded_x = np.round(soln.x.reshape(n,d)) # Rounding the solution\n",
    "    print(\"Over Capacity:\", np.sum(rounded_x.sum(axis=0) > cap))\n",
    "    print(\"Unassigned:\", np.sum(rounded_x.sum(axis=1) != 1.))\n",
    "    result = pd.DataFrame(\n",
    "        {\"Assignment\": np.nonzero(rounded_x)[1], \n",
    "         \"Happyness\": prefs.to_numpy().flatten()[rounded_x.flatten() == 1.]}, \n",
    "        index=prefs.index)\n",
    "    print(\"Unhappy Students:\", np.sum(result['Happyness'] == 0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_opt = compute_assignments(lab_prefs, lab_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_opt = compute_assignments(sec_prefs, sec_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_opt[\"Happyness\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Section Happyness\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.xlabel(\"Happyness Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_opt[\"Happyness\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Section Happyness\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.xlabel(\"Happyness Score\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
